{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import packages, set up environment, and load model and evaluation data\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "model_name = \"RNN\"\n",
    "path = os.path.join('..', 'trained_models', model_name)\n",
    "## If needed, copy config dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load eval data and remove NaNs\n",
    "rewards = np.load(os.path.join(path+\"_reward_history.npy\"))\n",
    "success = np.load(os.path.join(path+\"_success_history.npy\"))\n",
    "states = np.load(os.path.join(path+\"_state_history.npy\"))\n",
    "actions = np.load(os.path.join(path+\"_action_history.npy\"))\n",
    "\n",
    "## Select only the states and actions that are not NaN\n",
    "nan_idx = np.isnan(states[:,:,0])\n",
    "states = states[~nan_idx]\n",
    "actions = actions[~nan_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot reward and success rate pdfs in evaluation data\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "ax[0].hist(rewards, bins=20)\n",
    "ax[0].set_xlabel(\"Reward\")\n",
    "ax[0].set_ylabel(\"Frequency\")\n",
    "ax[0].set_title(\"Reward Distribution\")\n",
    "\n",
    "ax[1].hist(success, bins=20)\n",
    "ax[1].set_xlabel(\"Success Rate\")\n",
    "ax[1].set_ylabel(\"Frequency\")\n",
    "ax[1].set_title(\"Success Rate Distribution\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot state and action pdfs in evaluation data\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize = (10,10))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.hist(states[:,i], bins = 100)\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_title('State '+str(i))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot state dicts conditioned on previous actions\n",
    "\n",
    "fig, axes = plt.subplots(n_obs, n_action, figsize = (10,10))\n",
    "for obs in range(n_obs):\n",
    "    for act in range(n_action):\n",
    "        axes[obs, act].hist(states[actions[:,act]==1,obs], bins = 100)\n",
    "        axes[obs, act].set_yscale('log')\n",
    "        axes[obs, act].set_title('State '+str(obs)+' | Action '+str(act))\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
